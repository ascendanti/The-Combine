# Research Report: Claude Framework Token Efficiency and Context Management

Generated: 2026-01-23T14:38:22

## Summary

Three repositories offer complementary approaches to token/context efficiency: claude-modular provides command modularity with progressive disclosure, claude-cognitive implements attention-based working memory with decay dynamics, and Claude-Code-Workflow offers multi-agent orchestration with context-first architecture. The highest-value integration is claude-cognitive attention router, which directly addresses our token consumption problem.

## Priority Rankings

| Repository | Priority | Key Value |
|------------|----------|-----------|
| GMaN1911/claude-cognitive | HIGH | Attention-based context routing reduces token bloat |
| oxygen-fragment/claude-modular | MEDIUM | Progressive disclosure patterns |
| catlog22/Claude-Code-Workflow | LOW | Multi-CLI overlaps with existing orchestration |

## 1. claude-cognitive (HIGH PRIORITY)

Source: https://github.com/GMaN1911/claude-cognitive

### Key Features
- Attention-based file injection with 3-tier system
- HOT (>0.8): Full file injection during active development
- WARM (0.25-0.8): Headers only for background awareness
- COLD (<0.25): Not injected
- 15% decay per turn for unused files
- Co-activation for related files
- Multi-instance coordination via Pool system
- History logging with attention scores

### Why This Matters
Our current system loads everything into context. The attention router would:
1. Reduce baseline token load by only injecting relevant files
2. Let context breathe - files fade when not discussed
3. Enable multi-day sessions by managing context naturally

### Integration Points
- context-router-v2.py can be adapted as a PreToolUse hook
- Pool system integrates with daemon/memory.py
- History logging complements handoff system
- Fits Phase 10 Cross-Session Learning goal

### Traction
310 stars, 22 forks in 4 days. Engineers from NASA, Microsoft, Amazon, NVIDIA engaged.

## 2. claude-modular (MEDIUM PRIORITY)

Source: https://github.com/oxygen-fragment/claude-modular

### Key Features
- Progressive disclosure (load only needed context)
- Modular instructions (just-in-time command loading)
- Context compression
- Hierarchical configuration (Project > Environment > Command)
- 30+ ready-to-use commands
- XML command structure with context/requirements/execution sections

### What to Adopt
- Environment-specific configs (dev/staging/prod)
- Command validation patterns
- Progressive context loading principle
- Command categories map to our agent specializations

### Integration
- Uses XML vs our YAML - conversion needed
- 269 stars

## 3. Claude-Code-Workflow (LOW PRIORITY)

Source: https://github.com/catlog22/Claude-Code-Workflow

### Key Features
- JSON-driven workflow state
- Multi-CLI orchestration (Gemini/Qwen/Codex)
- Workflow levels: lite-lite-lite through brainstorm:auto-parallel
- ACE (Augment Context Engine) for code search
- Hierarchical CLAUDE.md system

### What to Adopt
- Workflow level taxonomy (lite vs full planning)
- JSON task definitions for structured handoffs

### Why Low Priority
- Multi-CLI features overlap with existing orchestration
- Requires npm installation
- We already have oracle agent for external LLMs

## Comparison Matrix

| Feature | claude-cognitive | claude-modular | Claude-Code-Workflow |
|---------|------------------|----------------|----------------------|
| Token Reduction | HIGH (attention) | MEDIUM (progressive) | LOW |
| Context Persist | HIGH (multi-day) | LOW (per-command) | MEDIUM |
| Multi-Instance | YES (pool) | NO | NO |
| Hook Integration | Easy (Python) | Moderate (XML) | Moderate (npm) |

## Recommendations

### Quick Wins
1. Implement attention decay (15% per turn) in existing hooks
2. Add attention score metadata to handoff format
3. Adopt progressive disclosure principle for skills

### Full Integration Path
1. Clone claude-cognitive, examine context-router-v2.py
2. Adapt as PreToolUse hook with Windows path support
3. Integrate with daemon/metacognition.py for capability tracking
4. Test with multi-day session to measure token reduction

### Gotchas
- claude-cognitive assumes Linux paths - needs Windows adaptation
- claude-modular XML may conflict with our YAML skills
- Claude-Code-Workflow requires npm - we prefer Python

## Sources

1. https://github.com/oxygen-fragment/claude-modular
2. https://github.com/GMaN1911/claude-cognitive
3. https://github.com/catlog22/Claude-Code-Workflow
4. https://medium.com/@gman1911.gs/i-built-working-memory-for-claude-code-heres-what-happened-in-4-days-657c60712655
5. https://alexop.dev/posts/stop-bloating-your-claude-md-progressive-disclosure-ai-coding-tools/

